{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Architecture Documentation for Azure OpenAI and RAG-Based Solution\n",
        "\n",
        "## Overview\n",
        "This architecture integrates **Azure OpenAI**, **Retrieval-Augmented Generation (RAG)**, and a data ingestion pipeline to process, store, and retrieve information efficiently. Below is a detailed explanation of each component and its role in the system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(filename='awb_ai_app.png'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. **Components**\n",
        "\n",
        "#### **1.1 Easy IDA**\n",
        "- A user-facing interface for authentication and access control.\n",
        "- Ensures secure interaction with the system via **Route53 DNS**.\n",
        "\n",
        "#### **1.2 Web Application**\n",
        "- Acts as the primary interface for users to interact with the system.\n",
        "- Accepts user inputs (prompts) and sends them to downstream components for processing.\n",
        "\n",
        "#### **1.3 LangChain**\n",
        "- A framework used to manage prompt engineering.\n",
        "- Generates different types of prompts based on user personas:\n",
        "  - **Original Prompt**: Direct input from the user.\n",
        "  - **Prompt Based on Persona**: Tailored prompts based on user type (e.g., technical or humorous).\n",
        "\n",
        "#### **1.4 Azure OpenAI**\n",
        "- Processes prompts using AI models hosted on Azure.\n",
        "- Supports natural language understanding and generation tasks.\n",
        "\n",
        "#### **1.5 Retrieval-Augmented Generation (RAG)**\n",
        "- Enhances AI responses by retrieving relevant context from external knowledge bases.\n",
        "- Interacts with:\n",
        "  - **Open Search Vector DB**: Stores vectorized representations of ingested data for efficient retrieval.\n",
        "  - **ElasticCache**: Maintains chat history to provide context in ongoing conversations.\n",
        "\n",
        "#### **1.6 Data Ingestion App**\n",
        "- Responsible for ingesting unstructured data (e.g., text from Confluence).\n",
        "- Converts raw data into vectorized format for storage in Open Search Vector DB.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. **Workflow**\n",
        "\n",
        "#### **Step 1: User Interaction**\n",
        "- Users interact with the system via the web application.\n",
        "- Prompts are sent to LangChain for processing.\n",
        "\n",
        "#### **Step 2: Prompt Engineering**\n",
        "- LangChain generates tailored prompts based on:\n",
        "  - User persona (e.g., technical or humorous).\n",
        "  - Original input from the user.\n",
        "\n",
        "#### **Step 3: AI Processing**\n",
        "- Prompts are sent to Azure OpenAI for natural language processing.\n",
        "- Responses are enhanced using RAG by retrieving relevant information from:\n",
        "  - Open Search Vector DB (contextual data).\n",
        "  - ElasticCache (chat history).\n",
        "\n",
        "#### **Step 4: Data Ingestion**\n",
        "- The Data Ingestion App processes external data sources (e.g., Confluence text).\n",
        "- Stores vectorized representations in Open Search Vector DB for future retrieval.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. **Key Technologies**\n",
        "\n",
        "| Component              | Technology Used          |\n",
        "|------------------------|---------------------------|\n",
        "| Authentication         | Easy IDA, Route53 DNS    |\n",
        "| Web Application        | Streamlit                |\n",
        "| Prompt Engineering     | LangChain                |\n",
        "| AI Processing          | Azure OpenAI             |\n",
        "| Retrieval              | RAG                      |\n",
        "| Storage                | Open Search Vector DB, ElasticCache |\n",
        "| Data Ingestion         | Custom Data Ingestion App |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. **Benefits of This Architecture**\n",
        "\n",
        "1. **Scalability**: Cloud-based components like Azure OpenAI and AWS services ensure scalability.\n",
        "2. **Efficiency**: RAG enhances response quality by providing relevant context.\n",
        "3. **Flexibility**: LangChain allows dynamic prompt generation based on user needs.\n",
        "4. **Data Utilization**: The ingestion pipeline enables effective use of external knowledge sources.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "This architecture demonstrates a robust integration of AI capabilities with retrieval-based enhancements, making it suitable for applications requiring intelligent, context-aware responses.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
